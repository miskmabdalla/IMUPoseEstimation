{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c969a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib.util\n",
    "import sys\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from datetime import datetime\n",
    "from IPython.display import display  # Jupyter-safe\n",
    "from io import StringIO\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8709f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleSpec(name='torch', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f9033f9afe0>, origin='/home/fadluw/anaconda3/envs/misk/lib/python3.10/site-packages/torch/__init__.py', submodule_search_locations=['/home/fadluw/anaconda3/envs/misk/lib/python3.10/site-packages/torch'])\n"
     ]
    }
   ],
   "source": [
    "torch_spec = importlib.util.find_spec(\"torch\")\n",
    "print(torch_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59475276",
   "metadata": {},
   "source": [
    "Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3251339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "aligned_data_root = Path(\"aligned_dataset\")\n",
    "window_size = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09dbaa2",
   "metadata": {},
   "source": [
    "Load and Accumulate Data Across Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47750c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for all trials\n",
    "X_trials = []\n",
    "y_trials = []\n",
    "\n",
    "# Load aligned IMU and angle data from all trials\n",
    "for trial_dir in sorted(aligned_data_root.glob(\"trial_*\")):\n",
    "    X_path = trial_dir / \"X.csv\"\n",
    "    y_path = trial_dir / \"Y.csv\"\n",
    "    if not X_path.exists() or not y_path.exists():\n",
    "        print(f\"Missing data in {trial_dir}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    X_df = pd.read_csv(X_path)\n",
    "    y_df = pd.read_csv(y_path)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    X_df = X_df.drop(columns=['Millis'], errors='ignore')\n",
    "    y_df = y_df.drop(columns=['time'], errors='ignore')\n",
    "\n",
    "    assert len(X_df) == len(y_df), f\"Length mismatch in {trial_dir}\"\n",
    "\n",
    "    X_trials.append(X_df.values)\n",
    "    y_trials.append(y_df.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434af071",
   "metadata": {},
   "source": [
    " Concatenate and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c588b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all trials\n",
    "X_all = np.concatenate(X_trials, axis=0)\n",
    "y_all = np.concatenate(y_trials, axis=0)\n",
    "\n",
    "# Scale features and targets\n",
    "scaler_X = StandardScaler().fit(X_all)\n",
    "scaler_y = StandardScaler().fit(y_all)\n",
    "\n",
    "X_all_scaled = scaler_X.transform(X_all)\n",
    "y_all_scaled = scaler_y.transform(y_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae685a8",
   "metadata": {},
   "source": [
    "Apply Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56af54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(X, y, window_size):\n",
    "    X_windowed = []\n",
    "    y_windowed = []\n",
    "    for i in range(len(X) - window_size + 1):\n",
    "        X_windowed.append(X[i:i+window_size])\n",
    "        y_windowed.append(y[i+window_size-1])  # predict last frame\n",
    "    return np.array(X_windowed), np.array(y_windowed)\n",
    "\n",
    "X_all, y_all = create_windows(X_all_scaled, y_all_scaled, window_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799517a5",
   "metadata": {},
   "source": [
    "Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce9f79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 60% train, 40% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_all, y_all, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 20% val, 20% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53682896",
   "metadata": {},
   "source": [
    "Wrap in PyTorch Datasets and Check Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67bcc2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input shape: torch.Size([50, 30])\n",
      "Sample target shape: torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "# Wrap in PyTorch datasets\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(X_val, dtype=torch.float32),\n",
    "    torch.tensor(y_val, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "x0, y0 = train_dataset[0]\n",
    "print(\"Sample input shape:\", x0.shape)\n",
    "print(\"Sample target shape:\", y0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24dbef48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccelX_chest</th>\n",
       "      <th>AccelY_chest</th>\n",
       "      <th>AccelZ_chest</th>\n",
       "      <th>GyroX_chest</th>\n",
       "      <th>GyroY_chest</th>\n",
       "      <th>GyroZ_chest</th>\n",
       "      <th>AccelX_right_leg</th>\n",
       "      <th>AccelY_right_leg</th>\n",
       "      <th>AccelZ_right_leg</th>\n",
       "      <th>GyroX_right_leg</th>\n",
       "      <th>...</th>\n",
       "      <th>AccelZ_right_arm</th>\n",
       "      <th>GyroX_right_arm</th>\n",
       "      <th>GyroY_right_arm</th>\n",
       "      <th>GyroZ_right_arm</th>\n",
       "      <th>AccelX_left_arm</th>\n",
       "      <th>AccelY_left_arm</th>\n",
       "      <th>AccelZ_left_arm</th>\n",
       "      <th>GyroX_left_arm</th>\n",
       "      <th>GyroY_left_arm</th>\n",
       "      <th>GyroZ_left_arm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-4.340</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-11.060</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-13.580</td>\n",
       "      <td>-6.230</td>\n",
       "      <td>-1.330</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>-7.350</td>\n",
       "      <td>2.170</td>\n",
       "      <td>-0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-3.792</td>\n",
       "      <td>-1.534</td>\n",
       "      <td>-11.004</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-12.654</td>\n",
       "      <td>-8.077</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.792</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-6.227</td>\n",
       "      <td>2.173</td>\n",
       "      <td>-0.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.261</td>\n",
       "      <td>-3.929</td>\n",
       "      <td>-3.166</td>\n",
       "      <td>-10.819</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-8.432</td>\n",
       "      <td>-8.326</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-0.796</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>-4.230</td>\n",
       "      <td>2.706</td>\n",
       "      <td>-0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-4.627</td>\n",
       "      <td>-5.351</td>\n",
       "      <td>-10.670</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-9.703</td>\n",
       "      <td>-7.385</td>\n",
       "      <td>3.721</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>-0.432</td>\n",
       "      <td>-3.994</td>\n",
       "      <td>2.045</td>\n",
       "      <td>-0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.971</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-4.464</td>\n",
       "      <td>-6.365</td>\n",
       "      <td>-10.485</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-10.517</td>\n",
       "      <td>-10.129</td>\n",
       "      <td>3.406</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-6.260</td>\n",
       "      <td>0.949</td>\n",
       "      <td>-1.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8667</th>\n",
       "      <td>-0.940</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-6.115</td>\n",
       "      <td>-1.804</td>\n",
       "      <td>4.283</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-9.457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-14.638</td>\n",
       "      <td>4.156</td>\n",
       "      <td>-17.374</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>8.219</td>\n",
       "      <td>28.189</td>\n",
       "      <td>29.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>-0.944</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.038</td>\n",
       "      <td>2.332</td>\n",
       "      <td>-5.765</td>\n",
       "      <td>2.600</td>\n",
       "      <td>-0.926</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-3.912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>-16.731</td>\n",
       "      <td>0.340</td>\n",
       "      <td>-8.773</td>\n",
       "      <td>-0.792</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>12.960</td>\n",
       "      <td>20.106</td>\n",
       "      <td>34.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8669</th>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.054</td>\n",
       "      <td>9.001</td>\n",
       "      <td>-8.268</td>\n",
       "      <td>2.011</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-6.688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-15.440</td>\n",
       "      <td>-1.678</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>-0.754</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>23.668</td>\n",
       "      <td>15.518</td>\n",
       "      <td>38.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.066</td>\n",
       "      <td>13.113</td>\n",
       "      <td>-8.690</td>\n",
       "      <td>1.190</td>\n",
       "      <td>-0.944</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>-11.573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-10.556</td>\n",
       "      <td>-1.145</td>\n",
       "      <td>9.450</td>\n",
       "      <td>-0.721</td>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>20.761</td>\n",
       "      <td>21.690</td>\n",
       "      <td>34.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>-1.042</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>0.073</td>\n",
       "      <td>15.159</td>\n",
       "      <td>-8.534</td>\n",
       "      <td>0.457</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.149</td>\n",
       "      <td>-5.724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-3.599</td>\n",
       "      <td>0.119</td>\n",
       "      <td>16.898</td>\n",
       "      <td>-0.772</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-0.507</td>\n",
       "      <td>13.672</td>\n",
       "      <td>24.504</td>\n",
       "      <td>23.677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8672 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AccelX_chest  AccelY_chest  AccelZ_chest  GyroX_chest  GyroY_chest  \\\n",
       "0           -0.974        -0.158         0.247       -4.340       -0.910   \n",
       "1           -0.980        -0.165         0.252       -3.792       -1.534   \n",
       "2           -0.983        -0.164         0.261       -3.929       -3.166   \n",
       "3           -0.979        -0.163         0.258       -4.627       -5.351   \n",
       "4           -0.971        -0.178         0.250       -4.464       -6.365   \n",
       "...            ...           ...           ...          ...          ...   \n",
       "8667        -0.940        -0.069         0.031       -6.115       -1.804   \n",
       "8668        -0.944        -0.091         0.038        2.332       -5.765   \n",
       "8669        -0.967        -0.112         0.054        9.001       -8.268   \n",
       "8670        -0.995        -0.118         0.066       13.113       -8.690   \n",
       "8671        -1.042        -0.109         0.073       15.159       -8.534   \n",
       "\n",
       "      GyroZ_chest  AccelX_right_leg  AccelY_right_leg  AccelZ_right_leg  \\\n",
       "0         -11.060            -0.989            -0.250             0.010   \n",
       "1         -11.004            -0.984            -0.252             0.011   \n",
       "2         -10.819            -0.987            -0.245             0.009   \n",
       "3         -10.670            -0.989            -0.243             0.006   \n",
       "4         -10.485            -0.988            -0.245             0.005   \n",
       "...           ...               ...               ...               ...   \n",
       "8667        4.283            -0.969            -0.289            -0.103   \n",
       "8668        2.600            -0.926            -0.299            -0.056   \n",
       "8669        2.011            -0.921            -0.247            -0.058   \n",
       "8670        1.190            -0.944            -0.206            -0.138   \n",
       "8671        0.457            -0.938            -0.252            -0.149   \n",
       "\n",
       "      GyroX_right_leg  ...  AccelZ_right_arm  GyroX_right_arm  \\\n",
       "0               0.000  ...            -0.051          -13.580   \n",
       "1              -0.122  ...            -0.042          -12.654   \n",
       "2              -0.190  ...            -0.096           -8.432   \n",
       "3              -0.582  ...            -0.087           -9.703   \n",
       "4              -0.766  ...            -0.047          -10.517   \n",
       "...               ...  ...               ...              ...   \n",
       "8667           -9.457  ...            -0.168          -14.638   \n",
       "8668           -3.912  ...            -0.173          -16.731   \n",
       "8669           -6.688  ...            -0.175          -15.440   \n",
       "8670          -11.573  ...            -0.191          -10.556   \n",
       "8671           -5.724  ...            -0.225           -3.599   \n",
       "\n",
       "      GyroY_right_arm  GyroZ_right_arm  AccelX_left_arm  AccelY_left_arm  \\\n",
       "0              -6.230           -1.330           -0.797           -0.447   \n",
       "1              -8.077            0.058           -0.792           -0.451   \n",
       "2              -8.326            1.572           -0.796           -0.450   \n",
       "3              -7.385            3.721           -0.807           -0.433   \n",
       "4             -10.129            3.406           -0.807           -0.419   \n",
       "...               ...              ...              ...              ...   \n",
       "8667            4.156          -17.374           -0.763            0.152   \n",
       "8668            0.340           -8.773           -0.792            0.125   \n",
       "8669           -1.678           -0.449           -0.754            0.192   \n",
       "8670           -1.145            9.450           -0.721            0.279   \n",
       "8671            0.119           16.898           -0.772            0.218   \n",
       "\n",
       "      AccelZ_left_arm  GyroX_left_arm  GyroY_left_arm  GyroZ_left_arm  \n",
       "0              -0.423          -7.350           2.170          -0.140  \n",
       "1              -0.419          -6.227           2.173          -0.279  \n",
       "2              -0.426          -4.230           2.706          -0.079  \n",
       "3              -0.432          -3.994           2.045          -0.338  \n",
       "4              -0.436          -6.260           0.949          -1.591  \n",
       "...               ...             ...             ...             ...  \n",
       "8667           -0.485           8.219          28.189          29.638  \n",
       "8668           -0.455          12.960          20.106          34.967  \n",
       "8669           -0.370          23.668          15.518          38.936  \n",
       "8670           -0.408          20.761          21.690          34.221  \n",
       "8671           -0.507          13.672          24.504          23.677  \n",
       "\n",
       "[8672 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce1dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right ankle</th>\n",
       "      <th>left ankle</th>\n",
       "      <th>right knee</th>\n",
       "      <th>left knee</th>\n",
       "      <th>right hip</th>\n",
       "      <th>left hip</th>\n",
       "      <th>right shoulder</th>\n",
       "      <th>left shoulder</th>\n",
       "      <th>right elbow</th>\n",
       "      <th>left elbow</th>\n",
       "      <th>...</th>\n",
       "      <th>right thigh</th>\n",
       "      <th>left thigh</th>\n",
       "      <th>pelvis</th>\n",
       "      <th>trunk</th>\n",
       "      <th>shoulders</th>\n",
       "      <th>head</th>\n",
       "      <th>right arm</th>\n",
       "      <th>left arm</th>\n",
       "      <th>right forearm</th>\n",
       "      <th>left forearm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-38.866456</td>\n",
       "      <td>-68.533373</td>\n",
       "      <td>7.446345</td>\n",
       "      <td>5.135329</td>\n",
       "      <td>2.958860</td>\n",
       "      <td>3.836582</td>\n",
       "      <td>9.499746</td>\n",
       "      <td>8.100783</td>\n",
       "      <td>-6.346643</td>\n",
       "      <td>-7.807354</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.818647</td>\n",
       "      <td>-81.940925</td>\n",
       "      <td>2.390685</td>\n",
       "      <td>93.411106</td>\n",
       "      <td>0.944986</td>\n",
       "      <td>85.548986</td>\n",
       "      <td>-76.277761</td>\n",
       "      <td>-77.676724</td>\n",
       "      <td>-82.624404</td>\n",
       "      <td>-85.484078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38.343883</td>\n",
       "      <td>-67.663694</td>\n",
       "      <td>7.098845</td>\n",
       "      <td>5.211061</td>\n",
       "      <td>2.763779</td>\n",
       "      <td>3.813969</td>\n",
       "      <td>9.576901</td>\n",
       "      <td>7.943975</td>\n",
       "      <td>-6.655394</td>\n",
       "      <td>-8.003499</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.907602</td>\n",
       "      <td>-81.857412</td>\n",
       "      <td>2.413493</td>\n",
       "      <td>93.304981</td>\n",
       "      <td>0.619276</td>\n",
       "      <td>85.720766</td>\n",
       "      <td>-76.094480</td>\n",
       "      <td>-77.727406</td>\n",
       "      <td>-82.749874</td>\n",
       "      <td>-85.730905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-38.564056</td>\n",
       "      <td>-68.091949</td>\n",
       "      <td>7.233265</td>\n",
       "      <td>5.214349</td>\n",
       "      <td>2.744306</td>\n",
       "      <td>3.736667</td>\n",
       "      <td>9.660954</td>\n",
       "      <td>7.744906</td>\n",
       "      <td>-6.794059</td>\n",
       "      <td>-8.090523</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.852892</td>\n",
       "      <td>-81.860531</td>\n",
       "      <td>2.423980</td>\n",
       "      <td>93.230797</td>\n",
       "      <td>0.349706</td>\n",
       "      <td>85.798934</td>\n",
       "      <td>-75.936244</td>\n",
       "      <td>-77.852291</td>\n",
       "      <td>-82.730303</td>\n",
       "      <td>-85.942814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38.867967</td>\n",
       "      <td>-68.663526</td>\n",
       "      <td>7.427086</td>\n",
       "      <td>5.242732</td>\n",
       "      <td>2.715914</td>\n",
       "      <td>3.650176</td>\n",
       "      <td>9.714999</td>\n",
       "      <td>7.533809</td>\n",
       "      <td>-6.846494</td>\n",
       "      <td>-8.130385</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.788269</td>\n",
       "      <td>-81.854007</td>\n",
       "      <td>2.426682</td>\n",
       "      <td>93.137782</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>85.755406</td>\n",
       "      <td>-75.789184</td>\n",
       "      <td>-77.970374</td>\n",
       "      <td>-82.635678</td>\n",
       "      <td>-86.100759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-39.087929</td>\n",
       "      <td>-69.071104</td>\n",
       "      <td>7.536546</td>\n",
       "      <td>5.309117</td>\n",
       "      <td>2.611634</td>\n",
       "      <td>3.531403</td>\n",
       "      <td>9.696660</td>\n",
       "      <td>7.321739</td>\n",
       "      <td>-6.858430</td>\n",
       "      <td>-8.130518</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.750948</td>\n",
       "      <td>-81.831179</td>\n",
       "      <td>2.425955</td>\n",
       "      <td>92.996181</td>\n",
       "      <td>-0.150368</td>\n",
       "      <td>85.646848</td>\n",
       "      <td>-75.665922</td>\n",
       "      <td>-78.040843</td>\n",
       "      <td>-82.524352</td>\n",
       "      <td>-86.171361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8667</th>\n",
       "      <td>-22.447342</td>\n",
       "      <td>-607.760028</td>\n",
       "      <td>188.743687</td>\n",
       "      <td>-358.873602</td>\n",
       "      <td>-1.881603</td>\n",
       "      <td>10.083178</td>\n",
       "      <td>188.850720</td>\n",
       "      <td>-699.471566</td>\n",
       "      <td>721.165087</td>\n",
       "      <td>-556.179930</td>\n",
       "      <td>...</td>\n",
       "      <td>-89.796738</td>\n",
       "      <td>-77.831958</td>\n",
       "      <td>5.459484</td>\n",
       "      <td>95.548735</td>\n",
       "      <td>8.988479</td>\n",
       "      <td>77.853373</td>\n",
       "      <td>-79.064415</td>\n",
       "      <td>-787.386702</td>\n",
       "      <td>102.100672</td>\n",
       "      <td>-263.566631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>-21.076632</td>\n",
       "      <td>-609.004113</td>\n",
       "      <td>189.223845</td>\n",
       "      <td>-358.897816</td>\n",
       "      <td>-2.075384</td>\n",
       "      <td>10.120379</td>\n",
       "      <td>188.626724</td>\n",
       "      <td>-699.752464</td>\n",
       "      <td>721.522086</td>\n",
       "      <td>-556.221750</td>\n",
       "      <td>...</td>\n",
       "      <td>-89.859490</td>\n",
       "      <td>-77.663727</td>\n",
       "      <td>5.402113</td>\n",
       "      <td>95.417706</td>\n",
       "      <td>8.997585</td>\n",
       "      <td>77.754060</td>\n",
       "      <td>-79.157382</td>\n",
       "      <td>-787.536570</td>\n",
       "      <td>102.364704</td>\n",
       "      <td>-263.758320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8669</th>\n",
       "      <td>-19.904360</td>\n",
       "      <td>-609.743294</td>\n",
       "      <td>189.539555</td>\n",
       "      <td>-358.854063</td>\n",
       "      <td>-2.330769</td>\n",
       "      <td>10.171159</td>\n",
       "      <td>188.502615</td>\n",
       "      <td>-700.206764</td>\n",
       "      <td>721.620868</td>\n",
       "      <td>-556.028654</td>\n",
       "      <td>...</td>\n",
       "      <td>-89.967538</td>\n",
       "      <td>-77.465611</td>\n",
       "      <td>5.350489</td>\n",
       "      <td>95.270369</td>\n",
       "      <td>8.890905</td>\n",
       "      <td>77.469419</td>\n",
       "      <td>-79.134155</td>\n",
       "      <td>-787.843534</td>\n",
       "      <td>102.486713</td>\n",
       "      <td>-263.872188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>-19.493500</td>\n",
       "      <td>-609.548309</td>\n",
       "      <td>189.649674</td>\n",
       "      <td>-358.817074</td>\n",
       "      <td>-2.539074</td>\n",
       "      <td>10.227793</td>\n",
       "      <td>188.531232</td>\n",
       "      <td>-700.774812</td>\n",
       "      <td>721.432229</td>\n",
       "      <td>-555.489361</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.069378</td>\n",
       "      <td>-77.302511</td>\n",
       "      <td>5.310810</td>\n",
       "      <td>95.163903</td>\n",
       "      <td>8.632980</td>\n",
       "      <td>77.080014</td>\n",
       "      <td>-78.999072</td>\n",
       "      <td>-788.305116</td>\n",
       "      <td>102.433158</td>\n",
       "      <td>-263.794477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>-20.056823</td>\n",
       "      <td>-608.750807</td>\n",
       "      <td>189.555564</td>\n",
       "      <td>-358.978344</td>\n",
       "      <td>-2.632460</td>\n",
       "      <td>10.223720</td>\n",
       "      <td>188.753479</td>\n",
       "      <td>-701.305962</td>\n",
       "      <td>720.979109</td>\n",
       "      <td>-554.669629</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.147683</td>\n",
       "      <td>-77.291502</td>\n",
       "      <td>5.280862</td>\n",
       "      <td>95.148822</td>\n",
       "      <td>8.281942</td>\n",
       "      <td>76.832470</td>\n",
       "      <td>-78.761744</td>\n",
       "      <td>-788.821184</td>\n",
       "      <td>102.217366</td>\n",
       "      <td>-263.490813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8672 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      right ankle  left ankle  right knee   left knee  right hip   left hip  \\\n",
       "0      -38.866456  -68.533373    7.446345    5.135329   2.958860   3.836582   \n",
       "1      -38.343883  -67.663694    7.098845    5.211061   2.763779   3.813969   \n",
       "2      -38.564056  -68.091949    7.233265    5.214349   2.744306   3.736667   \n",
       "3      -38.867967  -68.663526    7.427086    5.242732   2.715914   3.650176   \n",
       "4      -39.087929  -69.071104    7.536546    5.309117   2.611634   3.531403   \n",
       "...           ...         ...         ...         ...        ...        ...   \n",
       "8667   -22.447342 -607.760028  188.743687 -358.873602  -1.881603  10.083178   \n",
       "8668   -21.076632 -609.004113  189.223845 -358.897816  -2.075384  10.120379   \n",
       "8669   -19.904360 -609.743294  189.539555 -358.854063  -2.330769  10.171159   \n",
       "8670   -19.493500 -609.548309  189.649674 -358.817074  -2.539074  10.227793   \n",
       "8671   -20.056823 -608.750807  189.555564 -358.978344  -2.632460  10.223720   \n",
       "\n",
       "      right shoulder  left shoulder  right elbow  left elbow  ...  \\\n",
       "0           9.499746       8.100783    -6.346643   -7.807354  ...   \n",
       "1           9.576901       7.943975    -6.655394   -8.003499  ...   \n",
       "2           9.660954       7.744906    -6.794059   -8.090523  ...   \n",
       "3           9.714999       7.533809    -6.846494   -8.130385  ...   \n",
       "4           9.696660       7.321739    -6.858430   -8.130518  ...   \n",
       "...              ...            ...          ...         ...  ...   \n",
       "8667      188.850720    -699.471566   721.165087 -556.179930  ...   \n",
       "8668      188.626724    -699.752464   721.522086 -556.221750  ...   \n",
       "8669      188.502615    -700.206764   721.620868 -556.028654  ...   \n",
       "8670      188.531232    -700.774812   721.432229 -555.489361  ...   \n",
       "8671      188.753479    -701.305962   720.979109 -554.669629  ...   \n",
       "\n",
       "      right thigh  left thigh    pelvis      trunk  shoulders       head  \\\n",
       "0      -82.818647  -81.940925  2.390685  93.411106   0.944986  85.548986   \n",
       "1      -82.907602  -81.857412  2.413493  93.304981   0.619276  85.720766   \n",
       "2      -82.852892  -81.860531  2.423980  93.230797   0.349706  85.798934   \n",
       "3      -82.788269  -81.854007  2.426682  93.137782   0.094621  85.755406   \n",
       "4      -82.750948  -81.831179  2.425955  92.996181  -0.150368  85.646848   \n",
       "...           ...         ...       ...        ...        ...        ...   \n",
       "8667   -89.796738  -77.831958  5.459484  95.548735   8.988479  77.853373   \n",
       "8668   -89.859490  -77.663727  5.402113  95.417706   8.997585  77.754060   \n",
       "8669   -89.967538  -77.465611  5.350489  95.270369   8.890905  77.469419   \n",
       "8670   -90.069378  -77.302511  5.310810  95.163903   8.632980  77.080014   \n",
       "8671   -90.147683  -77.291502  5.280862  95.148822   8.281942  76.832470   \n",
       "\n",
       "      right arm    left arm  right forearm  left forearm  \n",
       "0    -76.277761  -77.676724     -82.624404    -85.484078  \n",
       "1    -76.094480  -77.727406     -82.749874    -85.730905  \n",
       "2    -75.936244  -77.852291     -82.730303    -85.942814  \n",
       "3    -75.789184  -77.970374     -82.635678    -86.100759  \n",
       "4    -75.665922  -78.040843     -82.524352    -86.171361  \n",
       "...         ...         ...            ...           ...  \n",
       "8667 -79.064415 -787.386702     102.100672   -263.566631  \n",
       "8668 -79.157382 -787.536570     102.364704   -263.758320  \n",
       "8669 -79.134155 -787.843534     102.486713   -263.872188  \n",
       "8670 -78.999072 -788.305116     102.433158   -263.794477  \n",
       "8671 -78.761744 -788.821184     102.217366   -263.490813  \n",
       "\n",
       "[8672 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce1c56",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a06ea833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMULSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, fc_hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # self.fc_head = nn.Sequential(\n",
    "        #     nn.Linear(hidden_size, fc_hidden_size),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(fc_hidden_size, output_size)\n",
    "        # )\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(64, output_size)\n",
    "        # self.dropout1 = nn.Dropout(p=0.1)  # You can try 0.3 to start\n",
    "        # self.dropout2 = nn.Dropout(p=0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        # c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        # out, _ = self.lstm(x, (h0, c0))\n",
    "        # last_step_output = out[:, -1, :]  # Take output from last timestep\n",
    "\n",
    "        # return self.fc_head(last_step_output)\n",
    "        out, _ = self.lstm(x)\n",
    "        x = out[:, -1, :]\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        # x = self.dropout2(x)\n",
    "        x = self.relu3(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed066b",
   "metadata": {},
   "source": [
    "R² Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aadd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(pred, target):\n",
    "    target_mean = torch.mean(target, dim=0)\n",
    "    ss_total = torch.sum((target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((target - pred) ** 2)\n",
    "    return 1 - (ss_res / ss_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae57d540",
   "metadata": {},
   "source": [
    "Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca01dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup log directory\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "log_dir = os.path.join('logs', f'run_{timestamp}')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "LOG_PATH = os.path.join(log_dir, 'training_log.txt')\n",
    "csv_path = os.path.join(log_dir, 'metrics.csv')\n",
    "SAVE_STDOUT = True  # If True, also print to terminal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34431af9",
   "metadata": {},
   "source": [
    "CSV Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa43420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metrics CSV setup\n",
    "csv_fields = ['epoch', 'train_mse', 'train_mae', 'train_rmse', 'train_r2',\n",
    "              'val_mse', 'val_mae', 'val_rmse', 'val_r2']\n",
    "\n",
    "csv_file = open(csv_path, mode='w', newline='')\n",
    "csv_writer = csv.DictWriter(csv_file, fieldnames=csv_fields)\n",
    "csv_writer.writeheader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbb7d504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sample shape: torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "print(\"Target sample shape:\", train_dataset[0][1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff7a527",
   "metadata": {},
   "source": [
    "Logger Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e76c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualLogger:\n",
    "    def __init__(self, filepath, print_to_stdout=True):\n",
    "        self.log_file = open(filepath, 'w')\n",
    "        self.print_to_stdout = print_to_stdout\n",
    "\n",
    "    def log(self, text):\n",
    "        self.log_file.write(text + '\\n')\n",
    "        self.log_file.flush()\n",
    "        if self.print_to_stdout:\n",
    "            print(text)\n",
    "\n",
    "    def close(self):\n",
    "        self.log_file.close()\n",
    "\n",
    "logger = DualLogger(LOG_PATH, print_to_stdout=SAVE_STDOUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfdf30",
   "metadata": {},
   "source": [
    "Hyperparameters and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561902ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Training started: 2025-04-15 00:08:32\n",
      "Device: CUDA\n",
      "Hyperparameters:\n",
      "  Hidden Size   = 256\n",
      "  Num Layers    = 2\n",
      "  Batch Size    = 50\n",
      "  Epochs        = 20\n",
      "  Learning Rate = 0.001\n",
      "  Window Size   = 50\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "batch_size = 50\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Show config info\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"  Hidden Size   = {hidden_size}\")\n",
    "print(f\"  Num Layers    = {num_layers}\")\n",
    "print(f\"  Batch Size    = {batch_size}\")\n",
    "print(f\"  Epochs        = {epochs}\")\n",
    "print(f\"  Learning Rate = {learning_rate}\")\n",
    "print(f\"  Window Size   = {window_size}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save config to file\n",
    "hyperparams = {\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"window_size\": window_size,\n",
    "}\n",
    "with open(os.path.join(log_dir, 'hyperparameters.json'), 'w') as f:\n",
    "    json.dump(hyperparams, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ac4ef",
   "metadata": {},
   "source": [
    "Model, Optimizer, Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e8f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Model setup\n",
    "input_size = train_dataset[0][0].shape[1]\n",
    "output_size = train_dataset[0][1].shape[0]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = IMULSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "mae_loss_fn = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6f1b0",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea548948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "Epoch 1/20\n",
      "  Batch  100/1098 - Running MSE Loss: 0.9023\n",
      "  Batch  200/1098 - Running MSE Loss: 0.6856\n",
      "  Batch  300/1098 - Running MSE Loss: 0.5695\n",
      "  Batch  400/1098 - Running MSE Loss: 0.4744\n",
      "  Batch  500/1098 - Running MSE Loss: 0.4931\n",
      "  Batch  600/1098 - Running MSE Loss: 0.3873\n",
      "  Batch  700/1098 - Running MSE Loss: 0.4087\n",
      "  Batch  800/1098 - Running MSE Loss: 0.3129\n",
      "  Batch  900/1098 - Running MSE Loss: 0.2583\n",
      "  Batch 1000/1098 - Running MSE Loss: 0.2632\n",
      "  Batch 1098/1098 - Running MSE Loss: 0.2262\n",
      "  ↳ Train → MSE: 0.4537, MAE: 0.4151, RMSE: 0.6736, R²: 0.5338\n",
      "  ↳ Val   → MSE: 0.2295, MAE: 0.2969, RMSE: 0.4791, R²: 0.7628\n",
      "----------------------------------------------------------------------\n",
      "Epoch 2/20\n",
      "  Batch  100/1098 - Running MSE Loss: 0.1976\n",
      "  Batch  200/1098 - Running MSE Loss: 0.1898\n",
      "  Batch  300/1098 - Running MSE Loss: 0.2067\n",
      "  Batch  400/1098 - Running MSE Loss: 0.2013\n",
      "  Batch  500/1098 - Running MSE Loss: 0.1533\n",
      "  Batch  600/1098 - Running MSE Loss: 0.1546\n",
      "  Batch  700/1098 - Running MSE Loss: 0.1343\n",
      "  Batch  800/1098 - Running MSE Loss: 0.1323\n",
      "  Batch  900/1098 - Running MSE Loss: 0.1323\n",
      "  Batch 1000/1098 - Running MSE Loss: 0.1284\n",
      "  Batch 1098/1098 - Running MSE Loss: 0.1056\n",
      "  ↳ Train → MSE: 0.1581, MAE: 0.2322, RMSE: 0.3977, R²: 0.8361\n",
      "  ↳ Val   → MSE: 0.1009, MAE: 0.1788, RMSE: 0.3177, R²: 0.8957\n",
      "----------------------------------------------------------------------\n",
      "Epoch 3/20\n",
      "  Batch  100/1098 - Running MSE Loss: 0.1170\n",
      "  Batch  200/1098 - Running MSE Loss: 0.2387\n",
      "  Batch  300/1098 - Running MSE Loss: 0.1595\n",
      "  Batch  400/1098 - Running MSE Loss: 0.1367\n",
      "  Batch  500/1098 - Running MSE Loss: 0.1095\n",
      "  Batch  600/1098 - Running MSE Loss: 0.0954\n",
      "  Batch  700/1098 - Running MSE Loss: 0.0893\n",
      "  Batch  800/1098 - Running MSE Loss: 0.0915\n",
      "  Batch  900/1098 - Running MSE Loss: 0.0768\n",
      "  Batch 1000/1098 - Running MSE Loss: 0.0778\n",
      "  Batch 1098/1098 - Running MSE Loss: 0.0704\n",
      "  ↳ Train → MSE: 0.1150, MAE: 0.1922, RMSE: 0.3391, R²: 0.8808\n",
      "  ↳ Val   → MSE: 0.0726, MAE: 0.1540, RMSE: 0.2695, R²: 0.9252\n",
      "----------------------------------------------------------------------\n",
      "Epoch 4/20\n",
      "  Batch  100/1098 - Running MSE Loss: 0.0662\n",
      "  Batch  200/1098 - Running MSE Loss: 0.0644\n",
      "  Batch  300/1098 - Running MSE Loss: 0.0627\n",
      "  Batch  400/1098 - Running MSE Loss: 0.0652\n",
      "  Batch  500/1098 - Running MSE Loss: 0.0672\n",
      "  Batch  600/1098 - Running MSE Loss: 0.0582\n",
      "  Batch  700/1098 - Running MSE Loss: 0.0551\n",
      "  Batch  800/1098 - Running MSE Loss: 0.0557\n",
      "  Batch  900/1098 - Running MSE Loss: 0.0531\n",
      "  Batch 1000/1098 - Running MSE Loss: 0.0553\n",
      "  Batch 1098/1098 - Running MSE Loss: 0.0545\n",
      "  ↳ Train → MSE: 0.0599, MAE: 0.1408, RMSE: 0.2447, R²: 0.9379\n",
      "  ↳ Val   → MSE: 0.0541, MAE: 0.1336, RMSE: 0.2327, R²: 0.9442\n",
      "----------------------------------------------------------------------\n",
      "Epoch 5/20\n",
      "  Batch  100/1098 - Running MSE Loss: 0.0473\n",
      "  Batch  200/1098 - Running MSE Loss: 0.0509\n",
      "  Batch  300/1098 - Running MSE Loss: 0.0488\n",
      "  Batch  400/1098 - Running MSE Loss: 0.0597\n",
      "  Batch  500/1098 - Running MSE Loss: 0.0554\n",
      "  Batch  600/1098 - Running MSE Loss: 0.0494\n",
      "  Batch  700/1098 - Running MSE Loss: 0.0623\n",
      "  Batch  800/1098 - Running MSE Loss: 0.0579\n",
      "  Batch  900/1098 - Running MSE Loss: 0.0675\n",
      "  Batch 1000/1098 - Running MSE Loss: 0.0672\n",
      "  Batch 1098/1098 - Running MSE Loss: 0.0485\n",
      "  ↳ Train → MSE: 0.0560, MAE: 0.1352, RMSE: 0.2366, R²: 0.9420\n",
      "  ↳ Val   → MSE: 0.0509, MAE: 0.1284, RMSE: 0.2256, R²: 0.9475\n",
      "----------------------------------------------------------------------\n",
      "Epoch 6/20\n",
      "  Batch  100/1098 - Running MSE Loss: 0.0435\n",
      "  Batch  200/1098 - Running MSE Loss: 0.0393\n",
      "  Batch  300/1098 - Running MSE Loss: 0.0402\n",
      "  Batch  400/1098 - Running MSE Loss: 0.0381\n",
      "  Batch  500/1098 - Running MSE Loss: 0.0440\n",
      "  Batch  600/1098 - Running MSE Loss: 0.0537\n",
      "  Batch  700/1098 - Running MSE Loss: 0.0807\n",
      "  Batch  800/1098 - Running MSE Loss: 0.0673\n",
      "  Batch  900/1098 - Running MSE Loss: 0.0541\n",
      "  Batch 1000/1098 - Running MSE Loss: 0.0454\n",
      "  Batch 1098/1098 - Running MSE Loss: 0.0374\n",
      "  ↳ Train → MSE: 0.0495, MAE: 0.1258, RMSE: 0.2226, R²: 0.9485\n",
      "  ↳ Val   → MSE: 0.0358, MAE: 0.1116, RMSE: 0.1891, R²: 0.9630\n",
      "----------------------------------------------------------------------\n",
      "Epoch 7/20\n",
      "  Batch  100/1098 - Running MSE Loss: 0.0341\n",
      "  Batch  200/1098 - Running MSE Loss: 0.0321\n",
      "  Batch  300/1098 - Running MSE Loss: 0.0310\n",
      "  Batch  400/1098 - Running MSE Loss: 0.0297\n",
      "  Batch  500/1098 - Running MSE Loss: 0.0298\n",
      "  Batch  600/1098 - Running MSE Loss: 0.0303\n",
      "  Batch  700/1098 - Running MSE Loss: 0.0304\n",
      "  Batch  800/1098 - Running MSE Loss: 0.0301\n",
      "  Batch  900/1098 - Running MSE Loss: 0.0250\n",
      "  Batch 1000/1098 - Running MSE Loss: 0.0307\n",
      "  Batch 1098/1098 - Running MSE Loss: 0.0348\n",
      "  ↳ Train → MSE: 0.0308, MAE: 0.1034, RMSE: 0.1755, R²: 0.9679\n",
      "  ↳ Val   → MSE: 0.0353, MAE: 0.1106, RMSE: 0.1880, R²: 0.9634\n",
      "----------------------------------------------------------------------\n",
      "Epoch 8/20\n",
      "  Batch  100/1098 - Running MSE Loss: 0.0434\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X_batch, y_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     14\u001b[0m     X_batch, y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     loss_mse \u001b[38;5;241m=\u001b[39m mse_loss_fn(pred, y_batch)\n\u001b[1;32m     18\u001b[0m     loss_mae \u001b[38;5;241m=\u001b[39m mae_loss_fn(pred, y_batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/misk/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/misk/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[11], line 39\u001b[0m, in \u001b[0;36mIMULSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# x = self.dropout1(x)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# x = self.dropout2(x)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n",
      "File \u001b[0;32m~/anaconda3/envs/misk/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/misk/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/misk/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.log(f\"\\nStarting training for {epochs} epochs...\\n\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    logger.log(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train_loss_mse = 0\n",
    "    train_loss_mae = 0\n",
    "    train_r2_total = 0\n",
    "    train_samples = 0\n",
    "\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        pred = model(X_batch)\n",
    "        loss_mse = mse_loss_fn(pred, y_batch)\n",
    "        loss_mae = mae_loss_fn(pred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_mse.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size_actual = X_batch.size(0)\n",
    "        train_loss_mse += loss_mse.item() * batch_size_actual\n",
    "        train_loss_mae += loss_mae.item() * batch_size_actual\n",
    "        train_r2_total += r2_score(pred.detach(), y_batch).item() * batch_size_actual\n",
    "        train_samples += batch_size_actual\n",
    "\n",
    "        running_loss += loss_mse.item()\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            avg_batch_loss = running_loss / min(100, (batch_idx + 1))\n",
    "            logger.log(f\"  Batch {batch_idx+1:>4}/{len(train_loader)} - Running MSE Loss: {avg_batch_loss:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_train_mse = train_loss_mse / train_samples\n",
    "    avg_train_mae = train_loss_mae / train_samples\n",
    "    avg_train_rmse = avg_train_mse ** 0.5\n",
    "    avg_train_r2 = train_r2_total / train_samples\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss_mse = 0\n",
    "    val_loss_mae = 0\n",
    "    val_r2_total = 0\n",
    "    val_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "            pred = model(X_val)\n",
    "            loss_mse = mse_loss_fn(pred, y_val)\n",
    "            loss_mae = mae_loss_fn(pred, y_val)\n",
    "\n",
    "            batch_size_actual = X_val.size(0)\n",
    "            val_loss_mse += loss_mse.item() * batch_size_actual\n",
    "            val_loss_mae += loss_mae.item() * batch_size_actual\n",
    "            val_r2_total += r2_score(pred, y_val).item() * batch_size_actual\n",
    "            val_samples += batch_size_actual\n",
    "\n",
    "    avg_val_mse = val_loss_mse / val_samples\n",
    "    avg_val_mae = val_loss_mae / val_samples\n",
    "    avg_val_rmse = avg_val_mse ** 0.5\n",
    "    avg_val_r2 = val_r2_total / val_samples\n",
    "\n",
    "    # --- Epoch Summary ---\n",
    "    logger.log(f\"  ↳ Train → MSE: {avg_train_mse:.4f}, MAE: {avg_train_mae:.4f}, RMSE: {avg_train_rmse:.4f}, R²: {avg_train_r2:.4f}\")\n",
    "    logger.log(f\"  ↳ Val   → MSE: {avg_val_mse:.4f}, MAE: {avg_val_mae:.4f}, RMSE: {avg_val_rmse:.4f}, R²: {avg_val_r2:.4f}\")\n",
    "    logger.log(\"-\" * 70)\n",
    "\n",
    "    # --- Save Epoch Metrics ---\n",
    "    csv_writer.writerow({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_mse': avg_train_mse,\n",
    "        'train_mae': avg_train_mae,\n",
    "        'train_rmse': avg_train_rmse,\n",
    "        'train_r2': avg_train_r2,\n",
    "        'val_mse': avg_val_mse,\n",
    "        'val_mae': avg_val_mae,\n",
    "        'val_rmse': avg_val_rmse,\n",
    "        'val_r2': avg_val_r2,\n",
    "    })\n",
    "    csv_file.flush()\n",
    "\n",
    "# --- Finalize ---\n",
    "csv_file.close()\n",
    "logger.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777883ed",
   "metadata": {},
   "source": [
    "Target Distribution Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect target (y) distribution in training and validation sets\n",
    "train_y = train_dataset[:][1]\n",
    "val_y = val_dataset[:][1]\n",
    "\n",
    "print(\"Train y mean/std:\", train_y.mean().item(), train_y.std().item())\n",
    "print(\"Val   y mean/std:\", val_y.mean().item(), val_y.std().item())\n",
    "print(\"Train y min/max:\", train_y.min().item(), train_y.max().item())\n",
    "print(\"Val   y min/max:\", val_y.min().item(), val_y.max().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73448d57",
   "metadata": {},
   "source": [
    "Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3dcedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model weights\n",
    "torch.save(model.state_dict(), \"imu_lstm_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdbb53c",
   "metadata": {},
   "source": [
    "Setup for Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5057774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function (if not already defined)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Wrap test data into a Dataset and DataLoader\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4212d",
   "metadata": {},
   "source": [
    "Run Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_test_batch, y_test_batch in test_loader:\n",
    "        X_test_batch = X_test_batch.to(device)\n",
    "        y_test_batch = y_test_batch.to(device)\n",
    "\n",
    "        pred = model(X_test_batch)\n",
    "        loss = criterion(pred, y_test_batch)\n",
    "\n",
    "        test_loss += loss.item() * X_test_batch.size(0)\n",
    "\n",
    "        all_preds.append(pred.cpu())\n",
    "        all_targets.append(y_test_batch.cpu())\n",
    "\n",
    "test_loss /= len(test_dataset)\n",
    "print(f\"Test MSE Loss: {test_loss:.4f}\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "y_true = torch.cat(all_targets).numpy()\n",
    "y_pred = torch.cat(all_preds).numpy()\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "test_metrics = {\n",
    "    \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "    \"R²\": r2_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b9988",
   "metadata": {},
   "source": [
    "Convert Test Outputs to NumPy (Optional for Analysis/Plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d03098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions and targets to NumPy for visualization or metrics\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee78bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_preds.shape, all_targets.shape)\n",
    "print(scaler_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d567f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# --- Step 0: Ensure tensors in all_preds and all_targets ---\n",
    "all_preds = [torch.as_tensor(p) if isinstance(p, np.ndarray) else p for p in all_preds]\n",
    "all_preds = [p.view(1, -1) if p.ndim == 1 else p for p in all_preds]\n",
    "\n",
    "all_targets = [torch.as_tensor(t) if isinstance(t, np.ndarray) else t for t in all_targets]\n",
    "all_targets = [t.view(1, -1) if t.ndim == 1 else t for t in all_targets]\n",
    "\n",
    "# --- Step 1: Concatenate tensors ---\n",
    "y_pred_tensor = torch.cat(all_preds, dim=0)\n",
    "y_true_tensor = torch.cat(all_targets, dim=0)\n",
    "\n",
    "# --- Step 2: Inverse transform to original scale ---\n",
    "y_pred_np = y_pred_tensor.numpy()\n",
    "y_true_np = y_true_tensor.numpy()\n",
    "\n",
    "y_pred_orig = scaler_y.inverse_transform(y_pred_np)\n",
    "y_true_orig = scaler_y.inverse_transform(y_true_np)\n",
    "\n",
    "# --- Step 3: Compute per-joint errors ---\n",
    "n_joints = y_true_orig.shape[1]\n",
    "mse_list = []\n",
    "rmse_list = []\n",
    "mae_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(n_joints):\n",
    "    mse = mean_squared_error(y_true_orig[:, i], y_pred_orig[:, i])\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true_orig[:, i], y_pred_orig[:, i])\n",
    "    r2 = r2_score(y_true_orig[:, i], y_pred_orig[:, i])\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "# --- Step 4: Organize into DataFrame ---\n",
    "joint_names = [\n",
    "    \"right ankle\", \"left ankle\", \"right knee\", \"left knee\", \"right hip\", \"left hip\",\n",
    "    \"right shoulder\", \"left shoulder\", \"right elbow\", \"left elbow\",\n",
    "    \"right foot\", \"left foot\", \"right shank\", \"left shank\",\n",
    "    \"right thigh\", \"left thigh\", \"pelvis\", \"trunk\", \"shoulders\", \"head\",\n",
    "    \"right arm\", \"left arm\", \"right forearm\", \"left forearm\"\n",
    "]\n",
    "\n",
    "joint_errors = pd.DataFrame({\n",
    "    \"Joint\": joint_names,\n",
    "    \"MSE\": mse_list,\n",
    "    \"RMSE\": rmse_list,\n",
    "    \"MAE\": mae_list,\n",
    "    \"R2\": r2_list\n",
    "}).sort_values(by=\"RMSE\")\n",
    "\n",
    "# --- Step 5: Display best/worst joints ---\n",
    "print(\"✅ Best joints (lowest RMSE):\")\n",
    "print(joint_errors.head(5))\n",
    "print(\"\\n⚠️ Worst joints (highest RMSE):\")\n",
    "print(joint_errors.tail(5))\n",
    "\n",
    "# --- Step 6: Plot RMSE ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(joint_errors[\"Joint\"], joint_errors[\"RMSE\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"RMSE (degrees)\")\n",
    "plt.title(\"Per-Joint RMSE\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "plot_path = os.path.join(log_dir, \"per_joint_rmse.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Plot saved to: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb667d1",
   "metadata": {},
   "source": [
    "PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Load Metrics CSV ---\n",
    "metrics_path = log_dir  # Adjust path if needed\n",
    "metrics_csv = os.path.join(metrics_path, 'metrics.csv')\n",
    "df = pd.read_csv(metrics_csv)\n",
    "\n",
    "# --- Plot Configuration ---\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")  # for Matplotlib 3.6+\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(8, 12))\n",
    "\n",
    "metrics = [\n",
    "    (\"train_rmse\", \"val_rmse\", \"RMSE\"),\n",
    "    (\"train_r2\", \"val_r2\", \"R²\"),\n",
    "    (\"train_mse\", \"val_mse\", \"MSE\"),\n",
    "    (\"train_mae\", \"val_mae\", \"MAE\")\n",
    "]\n",
    "\n",
    "for idx, (train_col, val_col, label) in enumerate(metrics):\n",
    "    axs[idx].plot(df[\"epoch\"], df[train_col], label=f\"Train {label}\", marker='o')\n",
    "    axs[idx].plot(df[\"epoch\"], df[val_col], label=f\"Validation {label}\", marker='x')\n",
    "    axs[idx].set_title(f\"Training vs Validation {label}\", fontsize=11)\n",
    "    axs[idx].set_xlabel(\"Epoch\")\n",
    "    axs[idx].set_ylabel(label)\n",
    "    axs[idx].legend()\n",
    "    axs[idx].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- Save Plots ---\n",
    "fig.savefig(os.path.join(log_dir,\"training_validation_metrics.png\"), dpi=300)\n",
    "fig.savefig(os.path.join(log_dir,\"training_validation_metrics.pdf\"))\n",
    "\n",
    "print(\"✅ Saved: training_validation_metrics.png and training_validation_metrics.pdf\")\n",
    "\n",
    "## --- Plot Configuration ---\n",
    "# plt.style.use(\"seaborn-v0_8-whitegrid\")  # for Matplotlib 3.6+\n",
    "\n",
    "# fig, axs = plt.subplots(4, 1, figsize=(8, 12))\n",
    "\n",
    "# metrics = [\n",
    "#     (\"train_rmse\", \"val_rmse\", \"RMSE\"),\n",
    "#     (\"train_r2\", \"val_r2\", \"R²\"),\n",
    "#     (\"train_mse\", \"val_mse\", \"MSE\"),\n",
    "#     (\"train_mae\", \"val_mae\", \"MAE\")\n",
    "# ]\n",
    "\n",
    "# for idx, (train_col, val_col, label) in enumerate(metrics):\n",
    "#     axs[idx].plot(df[\"epoch\"], df[train_col], label=f\"Train {label}\", marker='o')\n",
    "#     axs[idx].plot(df[\"epoch\"], df[val_col], label=f\"Validation {label}\", marker='x')\n",
    "\n",
    "#     # --- Use test_metrics dict to draw test line ---\n",
    "#     test_value = test_metrics[label]\n",
    "#     axs[idx].axhline(y=test_value, color='red', linestyle='--', label=f\"Test {label}\")\n",
    "\n",
    "#     axs[idx].set_title(f\"Training vs Validation {label}\", fontsize=11)\n",
    "#     axs[idx].set_xlabel(\"Epoch\")\n",
    "#     axs[idx].set_ylabel(label)\n",
    "#     axs[idx].legend()\n",
    "#     axs[idx].grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # --- Save Plots ---\n",
    "# fig.savefig(os.path.join(log_dir,\"training_validation_metrics_with_test.png\"), dpi=300)\n",
    "# fig.savefig(os.path.join(log_dir,\"training_validation_metrics_with_test.pdf\"))\n",
    "\n",
    "# print(\"✅ Saved: training_validation_metrics_with_test.png and training_validation_metrics_with_test.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff68796",
   "metadata": {},
   "source": [
    "Test Data / Summary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# --- Load last row from CSV ---\n",
    "# df = pd.read_csv(\"logs/run_2025-04-13_12-32-27/metrics.csv\")\n",
    "df = pd.read_csv(os.path.join(log_dir,\"metrics.csv\"))\n",
    "final_row = df.iloc[-1]\n",
    "\n",
    "# --- Train & Val Metrics ---\n",
    "final_metrics = {\n",
    "    \"Train\": {\n",
    "        \"RMSE\": final_row[\"train_rmse\"],\n",
    "        \"MAE\": final_row[\"train_mae\"],\n",
    "        \"R²\": final_row[\"train_r2\"]\n",
    "    },\n",
    "    \"Val\": {\n",
    "        \"RMSE\": final_row[\"val_rmse\"],\n",
    "        \"MAE\": final_row[\"val_mae\"],\n",
    "        \"R²\": final_row[\"val_r2\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Compute Test Metrics from loader ---\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for X_test_batch, y_test_batch in test_loader:\n",
    "        X_test_batch = X_test_batch.to(device)\n",
    "        y_test_batch = y_test_batch.to(device)\n",
    "        pred = model(X_test_batch)\n",
    "        all_preds.append(pred.cpu())\n",
    "        all_targets.append(y_test_batch.cpu())\n",
    "\n",
    "y_true = torch.cat(all_targets).numpy()\n",
    "y_pred = torch.cat(all_preds).numpy()\n",
    "\n",
    "final_metrics[\"Test\"] = {\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "    \"R²\": r2_score(y_true, y_pred)\n",
    "}\n",
    "\n",
    "# --- Plot one figure per metric ---\n",
    "for metric in [\"RMSE\", \"MAE\", \"R²\"]:\n",
    "    values = [final_metrics[split][metric] for split in [\"Train\", \"Val\", \"Test\"]]\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.bar([\"Train\", \"Val\", \"Test\"], values, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(f\"{metric} by Data Split\")\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(log_dir,\"final_{metric.lower()}_by_split.png\"), dpi=300)\n",
    "\n",
    "    print(f\"✅ Saved: final_{metric.lower()}_by_split.png\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
