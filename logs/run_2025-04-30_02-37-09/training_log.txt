
Starting training for 50 epochs...

  Batch  100/721 – Scaled MSE Loss: 1439.9542
  Batch  200/721 – Scaled MSE Loss: 1483.3450
  Batch  300/721 – Scaled MSE Loss: 1232.2354
  Batch  400/721 – Scaled MSE Loss: 1044.1947
  Batch  500/721 – Scaled MSE Loss: 840.5040
  Batch  600/721 – Scaled MSE Loss: 844.4485
  Batch  700/721 – Scaled MSE Loss: 868.3782
  Batch  721/721 – Scaled MSE Loss: 865.5516
Epoch 1/50
  ↳ Train (deg) → MSE: 1118.54, MAE: 20.64, RMSE: 33.44°, R²: 0.5641
  ↳ Val   (deg) → MSE: 3766.09, MAE: 36.20, RMSE: 61.37°, R²: -0.4235
----------------------------------------------------------------------
  Batch  100/721 – Scaled MSE Loss: 734.0974
  Batch  200/721 – Scaled MSE Loss: 564.5345
  Batch  300/721 – Scaled MSE Loss: 570.4564
  Batch  400/721 – Scaled MSE Loss: 611.0334
  Batch  500/721 – Scaled MSE Loss: 765.8288
  Batch  600/721 – Scaled MSE Loss: 671.6866
  Batch  700/721 – Scaled MSE Loss: 724.4779
  Batch  721/721 – Scaled MSE Loss: 509.0753
Epoch 2/50
  ↳ Train (deg) → MSE: 617.26, MAE: 14.14, RMSE: 24.84°, R²: 0.7595
  ↳ Val   (deg) → MSE: 3710.55, MAE: 35.54, RMSE: 60.91°, R²: -0.4025
----------------------------------------------------------------------
  Batch  100/721 – Scaled MSE Loss: 476.3104
  Batch  200/721 – Scaled MSE Loss: 441.8058
  Batch  300/721 – Scaled MSE Loss: 578.7601
  Batch  400/721 – Scaled MSE Loss: 481.0886
  Batch  500/721 – Scaled MSE Loss: 428.3681
  Batch  600/721 – Scaled MSE Loss: 432.3510
  Batch  700/721 – Scaled MSE Loss: 493.1431
  Batch  721/721 – Scaled MSE Loss: 524.8079
Epoch 3/50
  ↳ Train (deg) → MSE: 476.69, MAE: 12.24, RMSE: 21.83°, R²: 0.8142
  ↳ Val   (deg) → MSE: 4028.46, MAE: 36.94, RMSE: 63.47°, R²: -0.5226
----------------------------------------------------------------------
  ↳ No improvement for 1 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 334.5409
  Batch  200/721 – Scaled MSE Loss: 426.4656
  Batch  300/721 – Scaled MSE Loss: 450.1084
  Batch  400/721 – Scaled MSE Loss: 448.2502
  Batch  500/721 – Scaled MSE Loss: 482.9020
  Batch  600/721 – Scaled MSE Loss: 304.2296
  Batch  700/721 – Scaled MSE Loss: 402.5531
  Batch  721/721 – Scaled MSE Loss: 443.8716
Epoch 4/50
  ↳ Train (deg) → MSE: 414.84, MAE: 11.36, RMSE: 20.37°, R²: 0.8383
  ↳ Val   (deg) → MSE: 4215.48, MAE: 37.17, RMSE: 64.93°, R²: -0.5933
----------------------------------------------------------------------
  ↳ No improvement for 2 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 312.3813
  Batch  200/721 – Scaled MSE Loss: 377.0990
  Batch  300/721 – Scaled MSE Loss: 492.5684
  Batch  400/721 – Scaled MSE Loss: 576.9186
  Batch  500/721 – Scaled MSE Loss: 407.9078
  Batch  600/721 – Scaled MSE Loss: 343.3890
  Batch  700/721 – Scaled MSE Loss: 367.3766
  Batch  721/721 – Scaled MSE Loss: 301.9074
Epoch 5/50
  ↳ Train (deg) → MSE: 403.54, MAE: 11.09, RMSE: 20.09°, R²: 0.8427
  ↳ Val   (deg) → MSE: 4131.08, MAE: 36.78, RMSE: 64.27°, R²: -0.5614
----------------------------------------------------------------------
  ↳ No improvement for 3 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 333.8522
  Batch  200/721 – Scaled MSE Loss: 310.4099
  Batch  300/721 – Scaled MSE Loss: 440.6680
  Batch  400/721 – Scaled MSE Loss: 392.2326
  Batch  500/721 – Scaled MSE Loss: 236.8990
  Batch  600/721 – Scaled MSE Loss: 394.1553
  Batch  700/721 – Scaled MSE Loss: 353.7121
  Batch  721/721 – Scaled MSE Loss: 402.1677
Epoch 6/50
  ↳ Train (deg) → MSE: 348.69, MAE: 10.37, RMSE: 18.67°, R²: 0.8641
  ↳ Val   (deg) → MSE: 4016.76, MAE: 35.61, RMSE: 63.38°, R²: -0.5182
----------------------------------------------------------------------
  ↳ No improvement for 4 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 383.7822
  Batch  200/721 – Scaled MSE Loss: 616.9436
  Batch  300/721 – Scaled MSE Loss: 349.8996
  Batch  400/721 – Scaled MSE Loss: 334.5328
  Batch  500/721 – Scaled MSE Loss: 253.7803
  Batch  600/721 – Scaled MSE Loss: 260.9691
  Batch  700/721 – Scaled MSE Loss: 266.9945
  Batch  721/721 – Scaled MSE Loss: 281.9477
Epoch 7/50
  ↳ Train (deg) → MSE: 328.52, MAE: 10.07, RMSE: 18.13°, R²: 0.8720
  ↳ Val   (deg) → MSE: 4044.34, MAE: 35.76, RMSE: 63.60°, R²: -0.5286
----------------------------------------------------------------------
  ↳ No improvement for 5 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 243.9283
  Batch  200/721 – Scaled MSE Loss: 241.5547
  Batch  300/721 – Scaled MSE Loss: 263.3511
  Batch  400/721 – Scaled MSE Loss: 336.6929
  Batch  500/721 – Scaled MSE Loss: 250.5645
  Batch  600/721 – Scaled MSE Loss: 258.7746
  Batch  700/721 – Scaled MSE Loss: 297.5337
  Batch  721/721 – Scaled MSE Loss: 249.0957
Epoch 8/50
  ↳ Train (deg) → MSE: 281.51, MAE: 9.49, RMSE: 16.78°, R²: 0.8903
  ↳ Val   (deg) → MSE: 4032.33, MAE: 35.84, RMSE: 63.50°, R²: -0.5241
----------------------------------------------------------------------
  ↳ No improvement for 6 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 269.7473
  Batch  200/721 – Scaled MSE Loss: 260.9325
  Batch  300/721 – Scaled MSE Loss: 289.1270
  Batch  400/721 – Scaled MSE Loss: 222.5980
  Batch  500/721 – Scaled MSE Loss: 234.3601
  Batch  600/721 – Scaled MSE Loss: 186.9139
  Batch  700/721 – Scaled MSE Loss: 244.7693
  Batch  721/721 – Scaled MSE Loss: 336.7779
Epoch 9/50
  ↳ Train (deg) → MSE: 268.12, MAE: 9.28, RMSE: 16.37°, R²: 0.8955
  ↳ Val   (deg) → MSE: 4155.77, MAE: 36.59, RMSE: 64.47°, R²: -0.5708
----------------------------------------------------------------------
  ↳ No improvement for 7 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 248.7281
  Batch  200/721 – Scaled MSE Loss: 246.4196
  Batch  300/721 – Scaled MSE Loss: 271.9368
  Batch  400/721 – Scaled MSE Loss: 304.4796
  Batch  500/721 – Scaled MSE Loss: 232.8978
  Batch  600/721 – Scaled MSE Loss: 291.5095
  Batch  700/721 – Scaled MSE Loss: 239.0534
  Batch  721/721 – Scaled MSE Loss: 200.6450
Epoch 10/50
  ↳ Train (deg) → MSE: 257.78, MAE: 9.12, RMSE: 16.06°, R²: 0.8995
  ↳ Val   (deg) → MSE: 4138.71, MAE: 36.47, RMSE: 64.33°, R²: -0.5643
----------------------------------------------------------------------
  ↳ No improvement for 8 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 200.3346
  Batch  200/721 – Scaled MSE Loss: 239.7275
  Batch  300/721 – Scaled MSE Loss: 256.2776
  Batch  400/721 – Scaled MSE Loss: 281.3631
  Batch  500/721 – Scaled MSE Loss: 199.7237
  Batch  600/721 – Scaled MSE Loss: 268.6020
  Batch  700/721 – Scaled MSE Loss: 249.1999
  Batch  721/721 – Scaled MSE Loss: 182.3127
Epoch 11/50
  ↳ Train (deg) → MSE: 243.20, MAE: 8.91, RMSE: 15.59°, R²: 0.9052
  ↳ Val   (deg) → MSE: 4270.03, MAE: 37.01, RMSE: 65.35°, R²: -0.6139
----------------------------------------------------------------------
  ↳ No improvement for 9 consecutive epochs.
  Batch  100/721 – Scaled MSE Loss: 205.6471
  Batch  200/721 – Scaled MSE Loss: 214.2188
  Batch  300/721 – Scaled MSE Loss: 245.7836
  Batch  400/721 – Scaled MSE Loss: 246.6793
  Batch  500/721 – Scaled MSE Loss: 222.5827
  Batch  600/721 – Scaled MSE Loss: 255.6989
  Batch  700/721 – Scaled MSE Loss: 201.8113
  Batch  721/721 – Scaled MSE Loss: 238.1261
Epoch 12/50
  ↳ Train (deg) → MSE: 219.36, MAE: 8.63, RMSE: 14.81°, R²: 0.9145
  ↳ Val   (deg) → MSE: 4199.35, MAE: 36.54, RMSE: 64.80°, R²: -0.5872
----------------------------------------------------------------------
  ↳ No improvement for 10 consecutive epochs.
Early stopping triggered after 12 epochs (patience 10).
